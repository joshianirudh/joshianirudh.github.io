<a name="br1"></a> 



<a name="br2"></a> 

**PROBLEM STATEMENT**

**OUR CONTRIBUTION**

**TABLE OF**

**CONTENTS**

**PROPOSED METHODOLOGY**

**RESULTS & DISCUSSIONS**

**An Automated Workflow**

**for Deepfake**

**IMPLEMENTATION**

**CONCLUSION**

**Detection**



<a name="br3"></a> 

PROBLEM STATEMENT

The advent of AI has surfaced many concerns

around destructive activities such as

**misinformation** & defamation of individuals

using **deepfake** videos and images. The

instant dissemination of information

necessitates the need of a robust framework

that could detect visual forgery and flag such

content before it leads to harm to an individual

or builds chaos on a global scale.

3



<a name="br4"></a> 

OUR CONTRIBUTION

**Computationally cheap**

**workflow with comparable**

**performance to SOTA**

**1**

**2**

**A functioning**

**implementation as a**

**web app and API.**

[**LINK**](https://github.com/joshianirudh/deepfake-detector)[** ](https://github.com/joshianirudh/deepfake-detector)[TO**](https://github.com/joshianirudh/deepfake-detector)[** ](https://github.com/joshianirudh/deepfake-detector)[CODE**](https://github.com/joshianirudh/deepfake-detector)

4



<a name="br5"></a> 

PROPOSED METHODOLOGY

**Optical Flow**

**Across Frames**

**68 Facial**

**Landmarks**

**Workflow**

**Workflow**

5



<a name="br6"></a> 

IMPLEMENTATION



<a name="br7"></a> 

RESULTS & DISCUSSIONS

**112X**

**104X**

**84X**

**112x Lesser trainable parameters than DSP-**

**FWA.**

**104x Lesser trainable parameters than FWA.**

**84x lesser trainable parameters than**

**Xception Net.**

7



<a name="br8"></a> 

**RESULT TABLE**

**Data set**

**FF+**

**Data**

**Augmentation**

**Parameter Parameter**

**Celeb-DF**

**UADFV**

**MesoNet [1]**

**Two Stream [2]**

**FWA [5]**

**X**

**X**

**Capsule [4]**

**Xception [3]**

**DSP-FWA [6]**

**X**

**X**

**PROPOSED**

**METHOD**

**X**

8



<a name="br9"></a> 

Geometric features are effective in

detecting forged videos.

The proposed approach offers a best of

both world solution, guaranteeing

comparable performance to SOTA

methods with a significant reduction in

model parameters.

CONCLUSI

ON

This method depends on the accuracy

of position of facial landmarks and more

study is needed to improve this

accuracy through denoising and

alternative facial representations.

9



<a name="br10"></a> 

**THANK YOU**

